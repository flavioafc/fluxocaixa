# ADR-007: Garantia de Processamento de 50 Requisi√ß√µes por Segundo no Worker Consolidado

## 1Ô∏è‚É£ Contexto

O **Worker Consolidado** √© respons√°vel por processar os lan√ßamentos financeiros e calcular os saldos di√°rios. De acordo com os **requisitos n√£o-funcionais**, ele deve ser capaz de **processar 50 requisi√ß√µes por segundo**, garantindo **resili√™ncia, escalabilidade e efici√™ncia no processamento**.

Sem uma estrat√©gia adequada, o Worker pode:
- Ficar sobrecarregado, causando **atrasos** no processamento.
- N√£o processar a quantidade m√≠nima de **50 mensagens/segundo**.
- Gerar **perda de mensagens** caso a carga exceda sua capacidade.

---

## 2Ô∏è‚É£ Decis√£o

Para garantir que o **Worker Consolidado** atinja **50 requisi√ß√µes por segundo**, adotaremos a seguinte estrat√©gia:

1. **Paralelismo e Concurrency**  
   - Ajuste de **Prefetch Count** e **Concurrent Message Limit** no RabbitMQ.
   - Utiliza√ß√£o de **m√∫ltiplos threads** dentro do Worker.

2. **Escalabilidade Horizontal**  
   - M√∫ltiplas **r√©plicas do Worker** rodando simultaneamente.
   - **AutoScaling no Kubernetes** para aumentar inst√¢ncias dinamicamente.

3. **Configura√ß√£o do RabbitMQ para Alta Performance**  
   - Definir **PrefetchCount** e **Parallel Consumers**.
   - Uso de **Dead Letter Queue (DLQ)** para mensagens n√£o processadas.

4. **Monitoramento e Ajustes Autom√°ticos**  
   - **M√©tricas no Prometheus + Grafana**.
   - **AutoScaling baseado na fila do RabbitMQ**.

5. **Testes de Performance**  
   - Simula√ß√£o de carga usando **Locust** para validar a arquitetura.

---

## 3Ô∏è‚É£ Justificativa

| Estrat√©gia | Benef√≠cios |
|------------|-----------|
| **Paralelismo** | Permite processar m√∫ltiplas mensagens ao mesmo tempo. |
| **Escalabilidade Horizontal** | Se a carga aumentar, novas inst√¢ncias ser√£o criadas automaticamente. |
| **RabbitMQ Otimizado** | Melhora o throughput e evita gargalos. |
| **Monitoramento Ativo** | Permite ajustes em tempo real com AutoScaling. |
| **Testes de Carga** | Garante que o Worker atende ao requisito de 50 req/s. |

---

## 4Ô∏è‚É£ Implementa√ß√£o

### üîπ **1. Configura√ß√£o do Worker Consolidado**
No **Worker Consolidado**, devemos configurar o processamento paralelo das mensagens:

```csharp
public class WorkerConsolidado : BackgroundService
{
    private readonly IBusControl _bus;
    private readonly ILogger<WorkerConsolidado> _logger;

    public WorkerConsolidado(IBusControl bus, ILogger<WorkerConsolidado> logger)
    {
        _bus = bus;
        _logger = logger;
    }

    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        _logger.LogInformation("Worker Consolidado iniciado...");

        await _bus.ConnectReceiveEndpoint("fila-consolidado", e =>
        {
            e.PrefetchCount = 20; // Permite processar 20 mensagens simultaneamente
            e.ConcurrentMessageLimit = 10; // Limita a 10 mensagens concorrentes

            e.Handler<LancamentoCriadoEvent>(async context =>
            {
                await ProcessarLancamento(context.Message);
            });
        });

        await Task.Delay(-1, stoppingToken);
    }

    private async Task ProcessarLancamento(LancamentoCriadoEvent evento)
    {
        _logger.LogInformation($"Processando lan√ßamento {evento.Id}");

        // Simula√ß√£o de processamento
        await Task.Delay(50); // Ajuste conforme necess√°rio para performance

        _logger.LogInformation($"Lan√ßamento {evento.Id} processado!");
    }
}

```
### üîπ **2. Configura√ß√£o do RabbitMQ**
No MassTransit, configuramos a concorr√™ncia para maximizar a performance:

```csharp
builder.Services.AddMassTransit(x =>
{
    x.UsingRabbitMq((context, cfg) =>
    {
        cfg.Host("rabbitmq://localhost");

        cfg.ReceiveEndpoint("fila-consolidado", e =>
        {
            e.PrefetchCount = 20;
            e.ConcurrentMessageLimit = 10;
        });
    });
});
```

### üîπ **3. Configura√ß√£o de AutoScaling no Kubernetes**
No Kubernetes, ativamos o Horizontal Pod Autoscaler (HPA) para escalar os Workers conforme a fila do RabbitMQ.

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: worker-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: worker-consolidado
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: External
    external:
      metric:
        name: rabbitmq_queue_length
      target:
        type: AverageValue
        averageValue: 50
```
üìå Isso significa que sempre que houver mais de 50 mensagens na fila, o Kubernetes automaticamente criar√° mais Workers para process√°-las.

### üîπ **4. Teste de Carga com Locust**
Para validar que conseguimos atingir 50 mensagens por segundo, usamos Locust:

```python
from locust import HttpUser, task, between

class LancamentoTest(HttpUser):
    wait_time = between(1, 2)

    @task
    def enviar_lancamento(self):
        self.client.post("/api/lancamentos", json={
            "valor": 100.0,
            "tipo": "Credito",
            "descricao": "Teste de carga"
        })
```

Rodamos o teste com:

```bash
locust -f locustfile.py --host=http://localhost:5000
```
üìå Isso nos permite validar que a arquitetura suporta 50 mensagens por segundo.


## 5Ô∏è‚É£ Consequ√™ncias

‚úÖ Positivas

O Worker suportar√° 50 mensagens/segundo sem perder eventos.
Escalabilidade autom√°tica conforme a necessidade.
Monitoramento ativo para ajustar performance dinamicamente.
O sistema permanece resiliente mesmo em alta carga.

‚ùå Negativas

Aumento de custo com m√∫ltiplas inst√¢ncias no Kubernetes.
Complexidade adicional na configura√ß√£o de AutoScaling e RabbitMQ.

## 6Ô∏è‚É£ Decis√£o Final
Com base na an√°lise, adotamos a abordagem de escalabilidade horizontal, concorr√™ncia e auto-scaling para garantir que o Worker Consolidado processe 50 mensagens por segundo.

Essa decis√£o assegura que o sistema seja resiliente, perform√°tico e escal√°vel, atendendo aos requisitos n√£o-funcionais da solu√ß√£o.



